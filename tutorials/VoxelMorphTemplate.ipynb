{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bcdccb3b7c4485790e0fc49a5662eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fd96b948ae94754af7fe447b3985b2b",
              "IPY_MODEL_588ebab9ca7a4fec81ea76d47e6067ce",
              "IPY_MODEL_dc07e5481ec54f6a84e8fb36be9d6fa5"
            ],
            "layout": "IPY_MODEL_24e9172bf33d488f832c115562e1d305"
          }
        },
        "1fd96b948ae94754af7fe447b3985b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5d2d673dd104e5b931c96121bab44a0",
            "placeholder": "​",
            "style": "IPY_MODEL_e94763c0550f41a3b57c9d8c2d485f91",
            "value": "Training:   0%"
          }
        },
        "588ebab9ca7a4fec81ea76d47e6067ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea09d3d687f246b48821c949e2176ca3",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecf3d802e36a4ec4a25e115f17855072",
            "value": 0
          }
        },
        "dc07e5481ec54f6a84e8fb36be9d6fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7bdfbef1c54725bda63087ea0ae89b",
            "placeholder": "​",
            "style": "IPY_MODEL_778054bb7913480fbef435a9a1565b51",
            "value": " 0/100 ETA: ?s,  ?epochs/s"
          }
        },
        "24e9172bf33d488f832c115562e1d305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e5d2d673dd104e5b931c96121bab44a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e94763c0550f41a3b57c9d8c2d485f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea09d3d687f246b48821c949e2176ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecf3d802e36a4ec4a25e115f17855072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d7bdfbef1c54725bda63087ea0ae89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "778054bb7913480fbef435a9a1565b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYidisbHeYZO"
      },
      "source": [
        "# VoxelMorph Atlas Building Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ7Pzn-ksB6x"
      },
      "source": [
        "# tf 2.5 gives some weird errors. We'll go back to 2.4.1\n",
        "!pip uninstall tensorflow -y \n",
        "!pip install tensorflow==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.compat.v1.experimental.output_all_intermediates(True)"
      ],
      "metadata": {
        "id": "apACzOaqn3oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awBRZLC9Vbwh",
        "outputId": "d7e62a01-1185-4c56-b816-bee87c67d422"
      },
      "source": [
        "!pip install voxelmorph  # for all things voxelmorph/neurite\n",
        "!pip install tensorflow_addons  # for tqdm callbacks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: voxelmorph in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.4.1)\n",
            "Requirement already satisfied: neurite in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.1.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.21.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (0.18.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->voxelmorph) (1.5.2)\n",
            "Requirement already satisfied: pystrum in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (4.63.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->neurite->voxelmorph) (3.10.0.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.6.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (3.1.0)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzBWfnYCPO1a"
      },
      "source": [
        "# some imports we'll need throughout the demo\n",
        "import os\n",
        "\n",
        "# some third party very useful libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa  # for TQDM callback\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import nibabel as nib\n",
        "\n",
        "# our libraries\n",
        "import voxelmorph as vxm\n",
        "import neurite as ne"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2J071cQptvx"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZsrgMyNpth0"
      },
      "source": [
        "# turn off eager for this\n",
        "# need to do it due to some tf 2.0+ compatibility issues\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1lwekV6pLYz"
      },
      "source": [
        "# some helpful functions\n",
        "def plot_hist(hist):\n",
        "  plt.figure(figsize=(17,5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(hist.epoch, hist.history['loss'], '.-')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs');\n",
        "  plt.subplot(1, 2, 2)\n",
        "  nb_epochs = len(hist.epoch) // 2\n",
        "  plt.plot(hist.epoch[-nb_epochs:], hist.history['loss'][-nb_epochs:], '.-')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs');\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4Ml_e6kDOe8"
      },
      "source": [
        "# generally useful callback\n",
        "# unfortunately show_epoch_progress=True leaves a printout that we can't control (bad implementation in tfa...)\n",
        "tqdm_cb = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False, show_epoch_progress=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADanmU8xde-N"
      },
      "source": [
        "# Unconditional Template (MNIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ygb0ZFVDteQ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylmIFe6WpV29"
      },
      "source": [
        "# let's load up MNIST\n",
        "(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "x_train_all = x_train_all.astype('float')/255\n",
        "x_test_all = x_test_all.astype('float')/255\n",
        "\n",
        "x_train_all = np.pad(x_train_all, ((0, 0), (2, 2), (2, 2)), 'constant')[..., np.newaxis]\n",
        "x_test_all = np.pad(x_test_all, ((0, 0), (2, 2), (2, 2)), 'constant')[..., np.newaxis]\n",
        "\n",
        "vol_shape = list(x_train_all.shape[1:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsY8_Y0ZPS3P"
      },
      "source": [
        "# extract all 3s\n",
        "digit = 3\n",
        "\n",
        "x_train = x_train_all[y_train_all == digit, ...]\n",
        "y_train = y_train_all[y_train_all == digit]\n",
        "x_test = x_test_all[y_test_all == digit, ...].astype('float')/255\n",
        "y_test = y_test_all[y_test_all == digit]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBS7qK45digx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3aa1753-5bc7-48d9-ae54-a2b8921ddfb4"
      },
      "source": [
        "# prepare a simple generator. \n",
        "def template_gen(x, batch_size):\n",
        "  vol_shape = list(x.shape[1:-1])\n",
        "  zero = np.zeros([batch_size] + vol_shape + [2])\n",
        "  mean_atlas = np.repeat(  np.mean(x, 0, keepdims=True), batch_size, 0)\n",
        "\n",
        "  while True:\n",
        "    idx = np.random.randint(0, x.shape[0], batch_size)\n",
        "    img = x[idx, ...]\n",
        "    inputs = [mean_atlas, img]\n",
        "    outputs = [img, zero, zero, zero]\n",
        "    yield inputs, outputs\n",
        "\n",
        "# let's make sure the sizes make sense\n",
        "sample = next(template_gen(x_train, 8))\n",
        "[f.shape for f in sample[0]], [f.shape for f in sample[1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(8, 32, 32, 1), (8, 32, 32, 1)],\n",
              " [(8, 32, 32, 1), (8, 32, 32, 2), (8, 32, 32, 2), (8, 32, 32, 2)])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expFKVpnds54"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxf85UqIdFI5"
      },
      "source": [
        "enc_nf = [16, 32, 32, 32]\n",
        "dec_nf = [32, 32, 32, 32, 32, 16, 16]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "pLhmq98lPQlb",
        "outputId": "b2516cf9-36dd-428e-bc5a-08276c95c084"
      },
      "source": [
        "model = vxm.networks.TemplateCreation(vol_shape, nb_unet_features=[enc_nf, dec_nf])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LocalParamWithInput: Consider using neuron.layers.LocalParam()\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGhdphmgQaFo"
      },
      "source": [
        "# prepare losses and compile\n",
        "image_loss_func = vxm.losses.MSE().loss\n",
        "neg_loss_func = lambda _, y_pred: image_loss_func(model.references.atlas_tensor, y_pred)\n",
        "losses = [image_loss_func, neg_loss_func, vxm.losses.MSE().loss, vxm.losses.Grad('l2', loss_mult=2).loss]\n",
        "loss_weights = [0.5, 0.5, 1, 0.01]\n",
        "\n",
        "model.compile('adam', loss=losses, loss_weights=loss_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "4bcdccb3b7c4485790e0fc49a5662eb0",
            "1fd96b948ae94754af7fe447b3985b2b",
            "588ebab9ca7a4fec81ea76d47e6067ce",
            "dc07e5481ec54f6a84e8fb36be9d6fa5",
            "24e9172bf33d488f832c115562e1d305",
            "e5d2d673dd104e5b931c96121bab44a0",
            "e94763c0550f41a3b57c9d8c2d485f91",
            "ea09d3d687f246b48821c949e2176ca3",
            "ecf3d802e36a4ec4a25e115f17855072",
            "7d7bdfbef1c54725bda63087ea0ae89b",
            "778054bb7913480fbef435a9a1565b51"
          ]
        },
        "id": "uXy6KLvrSKbc",
        "outputId": "41327d34-cb3a-4ba2-d41d-f6fd2350d593"
      },
      "source": [
        "# train model\n",
        "gen = template_gen(x_train, batch_size=8)\n",
        "hist = model.fit(gen, epochs=100, steps_per_epoch=25, verbose=0, callbacks=[tqdm_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|           0/100 ETA: ?s,  ?epochs/s"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bcdccb3b7c4485790e0fc49a5662eb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-4ccf67285696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtqdm_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Setup work for each epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36mreset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m       \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4042\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4043\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4044\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    761\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m     is_initialized = session.run(\n\u001b[0;32m-> 1214\u001b[0;31m         [tf.compat.v1.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m   1215\u001b[0m     \u001b[0;31m# TODO(kathywu): Some metric variables loaded from SavedModel are never\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;31m# actually used, and do not have an initializer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nNode 'training/Adam/gradients/gradients/transformer/map/while_grad/transformer/map/while_grad': Connecting to invalid output 154 of source node transformer/map/while which has 154 outputs. Try using tf.compat.v1.experimental.output_all_intermediates(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg-XSIhMesyj"
      },
      "source": [
        "# visualize training\n",
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt-CPXfdD46S"
      },
      "source": [
        "## Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EynNvFplSeUP"
      },
      "source": [
        "# visualize learned atlas\n",
        "atlas = model.references.atlas_layer.get_weights()[0][..., 0]\n",
        "plt.imshow(atlas, cmap='gray')\n",
        "plt.axis('off');\n",
        "plt.title('atlas')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-t3ztxZgpW1"
      },
      "source": [
        "# Unconditional Template (2D Brain slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUu1VjrdD6_N"
      },
      "source": [
        "## Get Data\n",
        "This is data we released as part of neurite, please read more about it [here](https://github.com/adalca/medical-datasets/blob/master/neurite-oasis.md)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57q6VXORhg7b"
      },
      "source": [
        "# get the data\n",
        "!wget wget http://surfer.nmr.mgh.harvard.edu/ftp/data/neurite/data/neurite-oasis.2d.v1.0.tar -O data.tar\n",
        "!tar -xf data.tar;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gddK5393h5bM"
      },
      "source": [
        "# prepare data\n",
        "files = [f + '/slice_norm.nii.gz' for f in os.listdir('.') if f.startswith('OASIS_OAS1_')]\n",
        "vols = [nib.load(f).get_fdata() for f in tqdm(files)]\n",
        "x_vols = np.stack(vols, 0)\n",
        "vol_shape = x_vols.shape[1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY-xqHMzEF_J"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXokSB7KimLh"
      },
      "source": [
        "# get the model\n",
        "enc_nf = [16, 32, 32, 32]\n",
        "dec_nf = [32, 32, 32, 32, 32, 16, 16]\n",
        "model = vxm.networks.TemplateCreation(vol_shape, nb_unet_features=[enc_nf, dec_nf])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic1uHcGji5O6"
      },
      "source": [
        "# prepare losses\n",
        "image_loss_func = vxm.losses.MSE().loss\n",
        "neg_loss_func = lambda _, y_pred: image_loss_func(model.references.atlas_tensor, y_pred)\n",
        "losses = [image_loss_func, neg_loss_func, vxm.losses.MSE().loss, vxm.losses.Grad('l2', loss_mult=2).loss]\n",
        "loss_weights = [0.5, 0.5, 1, 0.01]\n",
        "\n",
        "model.compile('adam', loss=losses, loss_weights=loss_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U67yiOM-i6uW"
      },
      "source": [
        "# train\n",
        "gen = template_gen(x_vols, batch_size=2)\n",
        "hist = model.fit(gen, epochs=100, steps_per_epoch=25, verbose=0, callbacks=[tqdm_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGIhkpYIjKkx"
      },
      "source": [
        "# visualize optimization\n",
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AhA4oRWESAI"
      },
      "source": [
        "## Visualize Atlas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OylH0vLjBNz"
      },
      "source": [
        "atlas = model.references.atlas_layer.get_weights()[0][..., 0]\n",
        "plt.imshow(np.rot90(atlas, -1), cmap='gray')\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICiteHXdrf6R"
      },
      "source": [
        "# Conditional Template (MNIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6bCKmBVEU9F"
      },
      "source": [
        "## Data (all MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8KEw6EfreSA"
      },
      "source": [
        "# back to MNIST, all digits this time\n",
        "x_train = x_train_all\n",
        "y_train = y_train_all\n",
        "y_train_onehot = tf.keras.utils.to_categorical(y_train_all, 10)\n",
        "x_test = x_test_all\n",
        "y_test = y_train_all\n",
        "vol_shape = list(x_train.shape[1:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUWMZihir87g"
      },
      "source": [
        "# prepare a simple generator. \n",
        "def cond_template_gen(x, y, batch_size):\n",
        "  vol_shape = list(x.shape[1:-1])\n",
        "  zero = np.zeros([batch_size] + vol_shape + [2])\n",
        "  atlas = np.repeat(np.mean(x, 0, keepdims=True), batch_size, 0)\n",
        "\n",
        "  while True:\n",
        "    idx = np.random.randint(0, x.shape[0], batch_size)\n",
        "    img = x[idx, ...]\n",
        "    inputs = [y[idx, ...], atlas, img]\n",
        "\n",
        "    outputs = [img, zero, zero, zero]\n",
        "    yield inputs, outputs\n",
        "\n",
        "sample = next(cond_template_gen(x_train, y_train_onehot, 8))\n",
        "[f.shape for f in sample[0]], [f.shape for f in sample[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoXa0BCOEZ9P"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kybjrJWOyGRP"
      },
      "source": [
        "nf_enc = [16,32,32,32]\n",
        "nf_dec = [32,32,32,32,16,16,3] \n",
        "model = vxm.networks.ConditionalTemplateCreation(vol_shape, pheno_input_shape=[10], nb_unet_features=[enc_nf, dec_nf], conv_nb_features=16,\n",
        "                                                 conv_image_shape = [4, 4, 8], conv_nb_levels=4)\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC-g__CMyrNY"
      },
      "source": [
        "# prepare losses\n",
        "image_loss_func = vxm.losses.MSE().loss\n",
        "losses = [image_loss_func, vxm.losses.MSE().loss, vxm.losses.Grad('l2', loss_mult=2).loss, vxm.losses.MSE().loss]\n",
        "loss_weights = [1, 0.01, 0.03, 0]  # changed second-last to 0.01\n",
        "\n",
        "\n",
        "model.compile('adam', loss=losses, loss_weights=loss_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up_-WfXRytBP"
      },
      "source": [
        "# fit\n",
        "gen = cond_template_gen(x_train, y_train_onehot, batch_size=32)\n",
        "hist = model.fit(gen, epochs=100, steps_per_epoch=25, verbose=0, callbacks=[tqdm_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCJ7VHa20Ap7"
      },
      "source": [
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMn8olPSEhyc"
      },
      "source": [
        "## Visualize atlas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tJcqNHN1qNq"
      },
      "source": [
        "atlas_model = tf.keras.models.Model(model.inputs[:2], model.get_layer('atlas').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkHtBIkk1-8R"
      },
      "source": [
        "mean_atlas = np.repeat(np.mean(x_train, 0, keepdims=True), 10, 0)\n",
        "input_samples = [tf.keras.utils.to_categorical(np.arange(10), 10), mean_atlas]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9RxTOeu2idR"
      },
      "source": [
        "pred = atlas_model.predict(input_samples)\n",
        "ne.plot.slices([f.squeeze() for f in pred], cmaps=['gray']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLeWURKPizFg"
      },
      "source": [
        "## Video: Visualize conditional atlas in video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdIX-iUmSxBU"
      },
      "source": [
        "!pip install opencv-python\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQAwxbjKbHpv"
      },
      "source": [
        "output_video_filename = 'age_evolution.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAMsOk9ya8wc"
      },
      "source": [
        "nb_frames = 100\n",
        "fps = 5\n",
        "\n",
        "# create input samples. \n",
        "# Since we're dealing with categorical here with MNIST, we'll make a fake continuous space.\n",
        "# The result won't be sensible but it will give an idea of using videos.\n",
        "linspace = np.linspace(0, 10 - 1e-7, nb_frames)\n",
        "pheno = tf.keras.utils.to_categorical(np.floor(linspace), 10) * (linspace - np.floor(linspace))[..., np.newaxis]\n",
        "mean_atlas = np.repeat(np.mean(x_train, 0, keepdims=True), nb_frames, 0)\n",
        "\n",
        "# get the atlas predictions\n",
        "input_samples = [pheno, mean_atlas]\n",
        "pred = atlas_model.predict(input_samples, batch_size=32)\n",
        "\n",
        "# write file\n",
        "out = cv2.VideoWriter(output_video_filename, cv2.VideoWriter_fourcc(*'MP4V'), \n",
        "                      fps, tuple(vol_shape), isColor=False) \n",
        "for i in range(nb_frames):\n",
        "  frame = (np.clip(pred[i, ..., 0], 0, 1)*255).astype('uint8')\n",
        "  out.write(frame)\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKYjoe3XkbGX"
      },
      "source": [
        "# get file\n",
        "from google.colab import files\n",
        "files.download(output_video_filename) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAs4Hg9IvUD6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGMV205TMaUr"
      },
      "source": [
        "# Multi-Modal atlas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cih2GKuga8Ql"
      },
      "source": [
        "We're going to simulate a couple of variants of multi-modal atlases.  \n",
        "To simulate 'modalities', we'll use MNIST, and intensity-inverted MNIST. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJyOrGbvX24c"
      },
      "source": [
        "## Unpaired data variant (conditional on modality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkaxb6lasL9"
      },
      "source": [
        "We want to test building a multi-modal atlas with *unpaired* multi-modal data.  \n",
        "\n",
        "To simulate this, we'll take out the images of digit 3, and **split** the training dataset into two groups of images: in the first group keeping the images as they are, while in the second group using intensity-inversed images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpUBflcQeSIi"
      },
      "source": [
        "Since the images are unpaired, it's easy to learn a conditional template where the condition is the modality. \n",
        "\n",
        "If they were paired (see below), we could take advantage of the pairing by learning a single atlas with two channels (`src_feats=2`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuCbbKGwemhV"
      },
      "source": [
        "# extract data\n",
        "x_train3 = x_train_all[y_train_all == 3, ...]\n",
        "x_train3_inv = 1 - x_train3\n",
        "y_train3 = y_train_all[y_train_all == 3, ...] * 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps3QVbzDZNvh"
      },
      "source": [
        "# create unpaired data\n",
        "x_train3_mixed = np.concatenate([x_train3[::2, ...], x_train3_inv[1::2, ...]], 0)\n",
        "y_train3_mixed = np.concatenate([y_train3[::2], 1 + y_train3[1::2]], 0)\n",
        "y_train3_mixed_onehot = tf.keras.utils.to_categorical(y_train3_mixed, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBICXYNvenlR"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX2YbnpOzh9D"
      },
      "source": [
        "enc_nf = [16,32,32,32]\n",
        "dec_nf = [32,32,32,32,16,16,3] \n",
        "model = vxm.networks.ConditionalTemplateCreation(vol_shape, \n",
        "                                                 pheno_input_shape=[2], \n",
        "                                                 src_feats=1,\n",
        "                                                 nb_unet_features=[enc_nf, dec_nf], \n",
        "                                                 conv_nb_features=16,\n",
        "                                                 conv_image_shape=[4, 4, 8], \n",
        "                                                 conv_nb_levels=4)\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ov6IpGlzh93"
      },
      "source": [
        "# prepare losses\n",
        "image_loss_func = vxm.losses.MSE().loss\n",
        "losses = [image_loss_func, vxm.losses.MSE().loss, vxm.losses.Grad('l2', loss_mult=2).loss, vxm.losses.MSE().loss]\n",
        "loss_weights = [1, 0.01, 0.03, 0]  \n",
        "\n",
        "model.compile('adam', loss=losses, loss_weights=loss_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQMxqdGSzh95"
      },
      "source": [
        "# fit\n",
        "gen = cond_template_gen(x_train3_mixed, y_train3_mixed_onehot, batch_size=16)\n",
        "hist = model.fit(gen, epochs=100, steps_per_epoch=25, verbose=0, callbacks=[tqdm_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSkJVrG-zh96"
      },
      "source": [
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s5wasd1OODZ"
      },
      "source": [
        "### Visualize atlas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmdcDSGGOODa"
      },
      "source": [
        "atlas_model = tf.keras.models.Model(model.inputs[:2], model.get_layer('atlas').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpRs_GjIOODc"
      },
      "source": [
        "mean_atlas = np.repeat(np.mean(x_train3_mixed, 0, keepdims=True), 2, 0)\n",
        "input_samples = [tf.keras.utils.to_categorical(np.arange(2), 2), mean_atlas]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_s63Pj_OODd"
      },
      "source": [
        "pred = atlas_model.predict(input_samples)\n",
        "ne.plot.slices([f.squeeze() for f in pred], cmaps=['gray'], width=6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVKQMnE3Y18m"
      },
      "source": [
        "## Paired data variant (Multi-channel atlas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAHpzEVtazVB"
      },
      "source": [
        "Assuming we have paired data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-n_wRRvZRjg"
      },
      "source": [
        "# 2-channel data.\n",
        "x_train3_2channel = np.concatenate([x_train3, x_train3_inv], -1)\n",
        "x_train3_2channel.shape  # making sure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNpm3EV1koxR"
      },
      "source": [
        "# unfortunately we had a bug in the pypi version of voxelmorph for atlas_feats\n",
        "# let's get the dev branches\n",
        "!pip uninstall voxelmorph neurite pystrum -y \n",
        "!git clone -b dev --single-branch https://github.com/voxelmorph/voxelmorph\n",
        "!git clone -b dev --single-branch https://github.com/adalca/neurite\n",
        "!git clone -b dev --single-branch https://github.com/adalca/pystrum\n",
        "\n",
        "import sys\n",
        "sys.path = ['voxelmorph', 'neurite', 'pystrum'] + sys.path\n",
        "\n",
        "# fully unimport vxm, neurite, pystrum\n",
        "lst = [f for f in sys.modules if f.startswith('voxelmorph')]\n",
        "[sys.modules.pop(f) for f in lst]\n",
        "lst = [f for f in sys.modules if f.startswith('neurite')]\n",
        "[sys.modules.pop(f) for f in lst]\n",
        "lst = [f for f in sys.modules if f.startswith('pystrum')]\n",
        "[sys.modules.pop(f) for f in lst]\n",
        "\n",
        "# reimport\n",
        "import voxelmorph as vxm\n",
        "import neurite as ne"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvPALfPCa467"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiid9L7SQ91s"
      },
      "source": [
        "enc_nf = [16,32,32,32]\n",
        "dec_nf = [32,32,32,32,16,16,3] \n",
        "model = vxm.networks.TemplateCreation(vol_shape, nb_unet_features=[enc_nf, dec_nf], atlas_feats=2, src_feats=2)\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX67NpvYZcKm"
      },
      "source": [
        "# prepare losses and compile\n",
        "image_loss_func = vxm.losses.MSE().loss\n",
        "neg_loss_func = lambda _, y_pred: image_loss_func(model.references.atlas_tensor, y_pred)\n",
        "losses = [image_loss_func, neg_loss_func, vxm.losses.MSE().loss, vxm.losses.Grad('l2', loss_mult=2).loss]\n",
        "loss_weights = [0.5, 0.5, 1, 0.01]\n",
        "\n",
        "model.compile('adam', loss=losses, loss_weights=loss_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOuhaZKuZieh"
      },
      "source": [
        "# fit\n",
        "gen = template_gen(x_train3_2channel, batch_size=16)\n",
        "hist = model.fit(gen, epochs=100, steps_per_epoch=25, verbose=0, callbacks=[tqdm_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVtfvZK_kQ-V"
      },
      "source": [
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3shZXL99axDW"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSkFWpPLal-7"
      },
      "source": [
        "# visualize learned atlas\n",
        "atlas = model.references.atlas_layer.get_weights()[0]\n",
        "print(atlas.shape)\n",
        "ne.plot.slices([atlas[..., 0], atlas[..., 1]], cmaps=['gray'], width=6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u03dlk8ZbnlR"
      },
      "source": [
        "# a bit blurry, but not too bad. Probably need to play with the hyperparameters."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}